# Milestone 4 : Interpretation of data & Communication of Insights of data  

## Introduction

## Gettin Started

## LSTM neural network
It works by using special gates to allow each LSTM layer to take information from both previous layers and the current layer. The data goes through multiple gates (like forget gate, input gate, etc.) and various activation functions (like the tanh function, relu function) and is passed through the LSTM cells. The main advantage of this is that it allows each LSTM cell to remember patterns for a certain amount of time. The thing to be noted is that LSTM can remember important information and at the same time forget irrelevant information. The LSTM architectures is shown below:

## Youtube video


## Team Member
Tan Sia Hong

Tan Chang Jung
